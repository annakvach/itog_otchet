---
title: "otchet_part_1"
author: "anna kvach"
date: "12/16/2020"
output: 
  html_document:
    toc: true
    number_sections: true 
    toc_depth: 4  
    theme: united  
    highlight: tango  
---

# Introduction






# Obtain data

For or work needed forward and reverse reads and transcriptome assembly.

transcriptome assembly - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDJZ4X> - Trinity_2019filtered_Reference.fasta - was used

```{bash, eval=F, echo=T}
mkdir transcriptome_assembly
wget -P transcriptome_assembly https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/RXE6CF
```

There are two options how to obtain reads-data: with help of Sratoolkit and simple bash code or manually from EBLM-EBI. 

## Sratoolkit + simple bash 

Using this method, we created a simple bash program that receives a file.txt with sra identifiers as input. Our code uses the prefetch and fastq-dump programs from the Sratoolkit package, and as a result downloads forward and backward reads.


First of all we created a file.txt with all sra id on each line.

```{bash, eval=F, echo=T}
vi id.txt
```

```{bash, content of txt.file, eval=F, echo=T}
SRR11096622
SRR11096623
SRR11096624
SRR11096625
SRR11096626
SRR11096627
SRR11096628
SRR11096629
SRR11096630
SRR11096631
SRR11096632
SRR11096633
SRR11096634
SRR11096635
SRR11096636
SRR11096637
SRR11096638
SRR11096639
SRR11096640
```



After that sra_dowload_with_sratoolkit.sh was create.  

```{bash, sra_dowload_with_sratoolkit, eval=F, echo=T}
#!/bin/bash  
# for SRA files downloading with help of sratoolkit                                           
FILE=$1                            
while read id                      
do                                 
prefetch $id                       
echo "for $id prefetch done"       
fastq-dump --split-files --split-3 ${id}.sra
echo "for $id fastq-dump done"     
done < $FILE
```

And after that:

```{bash, eval=F, echo=T}
/path_to/sra_dowload_with_sratoolkit.sh sra_id.txt
```

In result you got for all samples SRRXXXXXXXX_1.fastq.gz (forward reads) and (revers reads) SRRXXXXXXXX_2.fastq.gz, and for some samples - SRRXXXXXXXX.fastq.gz - files without prefix. Files with no prefix are files of the remaining unpaired reads, and we did not use them.

```{bash, eval=F, echo=T}
mkdir /path_to/forward_and_revers_raw_reads # create dir for forward and revers raw reads
mkdir /path_to/bad_single_reads # create dir for unpaired reads

mv *_*.*  /path_to/forward_and_revers_raw_reads # dir for forward and revers raw reads - data for future analisis
mv *.f* /path_to/bad_single_reads # dir for remaining unpaired reads - did not use them
```


## Directly and manually from EBLM-EBI

Also data could be obtained directly and manually from EBLM-EBI - <https://www.ebi.ac.uk/ena/browser/view/PRJNA607082>. 

Files with forward reads have "_1" prefix (for ex. SRR11096622_1.fastq.gz) and files with reverse reads have "_2" prefix (for ex. SRR11096622_2.fastq.gz). Files with no prefix are files of the remaining unpaired reads, and we did not need them.

# First data quality assessment FastQC and MultiQC

## FastQC_1

```{bash, eval=F, echo=T}

# start to work with good paired reads
cd forward_and_revers_raw_reads 

# to unarchive all data  
gunzip *fastq.gz 

# create new dir for fastqc reports
mkdir /path_to/FastQC_1_for_raw_data 

# create fastqc reports in FastQC_1_for_raw_data
fastqc -t 10 -o /path_to/FastQC_1_for_raw_data * 
```

## MultiQC_1

```{bash, eval=F, echo=T}
# to summarising the output from numerous fastqc reports in one .html file
multiqc /path_to/FastQC_1_for_raw_data
```

Quality reports show problems with:

* 

* 

# Trim Galore + second FastQC after it

As we faced with adapters-problem we create file.fasta with adapters from <http://docs.blast2go.com/user-manual/tools-(pro-feature)/fastq-quality-check/#FASTQQualityCheck-PerBaseSequenceQuality>.


```{bash, eval=F, echo=T}
vi adapters.fasta
```

```{bash, eval=F, echo=T}
>Illumina_Universal_Adapter 
AGATCGGAAGAG
>Illumina_Small_RNA_3_Adapter
TGGAATTCTCGG
>Illumina_Small_RNA_5_Adapter
GATCGTCGGACT
```


```{bash, eval=F, echo=T}
#####
#!/bin/bash  
# for trimming with TrimGalore for forward and reverse reads                                           
FILE=$1                            
while read id                      
do                                     
/path_to/TrimGalore-0.6.6/trim_galore --paired --phred33 -q 20 --length 36 -stringency 1 -e 0.1 -a2 "file:/path_to/adapters.fasta" -o after_trim_galore_1  --fastqc ${id}_1.fastq ${id}_2.fastq 
echo "for $id fastq-dump done --split-3"     
done < $FILE
```

* -q 20 - remove low-quality reads with a Phred score cutoff of 20

* --length 36 - a minimum read length threshold of 36 bp

* -stringency 1 - a stringency parameter of 1 for adapter sequence overlap

* -e 0.1 - a maximum allowed error rate of (0.1) 

* -a2 "file:/path_to/adapters.fasta" - to specify individual adapter sequences from our file.fasta for the two reads of paired-end files

* -o after_trim_galore_1  - all output will be written to this directory 

* --fastqc - create fastQC report

* {$1}_1.fastq - forward reads 

* {$id}_2.fastq - reverse reads 

## MultiQC_2

```{bash, eval=F, echo=T}
multiqc /path_to/after_trim_galore_1
```

Quality reports show problems with:

* 

* 

# Rcorrector

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

/home/tools/rcorrector -p SRR11096622_1_val_1.fq SRR11096622_2_val_2.fq -p SRR11096623_1_val_1.fq SRR11096623_2_val_2.fq -od test_rcorrector_1


## MultiQC_3
```{bash, eval=F, echo=T}
multiqc /path_to/test_rcorrector_1
```


# Identify and remove over-represented sequences

Based on all FastQC reports table () and .fasta file (over_r_rRNA.fasta) with all over-represented sequences was created. 

Using over_r_rRNA.fasta with help of Blastn - (<https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome>) all unique sequences were identified.

* Database --> Standard databases (nr/nt) --> Nucleotide collection (nr/nt)

* Organism --> bryozoans (taxid:10205)

After that, it was indicated in the table opposite each sequence what it encodes.

## Bowtie2 - Remove over-represented sequences 

The example we used to complete this part. - <https://sites.google.com/site/wiki4metagenomics/tools/short-read/remove-host-sequences>

Bowtie2 database was created using fasta file with over-represented sequences.

```{bash, eval=F, echo=T}
bowtie2-build over_r_rRNA.fasta O_R_rRNA_DB
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        bowtie2 -p 14 -x /path_to/O_R_rRNA_DB \
        -1 /path_to/${ID}_1_val_1.cor.fq \
        -2 /path_to/${ID}_2_val_2.cor.fq \
        --un-conc /path_to/${ID}_rna_removed > ${ID}mapped_and_unmapped.sam

done < $FILE

```


```{bash, eval=F, echo=T}
/path_to/code_to_remove_o_r_rrna.sh id.txt
```



/mnt4/transciptome_compare/kvach/ncbi/public/sra/first_split_try/forward_and_revers_raw_reads/after_trim_galore_1/test_rcorrector_1/FOR_over_rep_remove

36 удалить 
скопировать ID_for_rrna_remove.txt
в с 36 до 40 оставить в ID_for_rrna_remove.txt

./code_to_remove_o_r_rrna.sh  ID_for_rrna_remove.txt - готово!

1) проверить, как все прошло в /mnt4/transciptome_compare/kvach/ncbi/public/sra/first_split_try/forward_and_revers_raw_reads/after_trim_galore_1/test_rcorrector_1/FOR_over_rep_remove

2) протестировать нижний блок


```{bash, eval=F, echo=T}
mkdir after_rna_remove 
cp id.txt ./after_rna_remove/id_1.txt
mv *_rna_removed* after_rna_remove 
```


```{bash, eval=F, echo=T}
vi for_rename.sh
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        mv ${ID}_rna_removed.1 ${ID}_rna_removed_1_F.fastq
        mv ${ID}_rna_removed.2 ${ID}_rna_removed_2_R.fastq

done < $FILE

```

```{bash, eval=F, echo=T}
chmod +x for_rename.sh
```

```{bash, eval=F, echo=T}
mkdir fastq_reports_after_rna_remove
fastqc -o fastq_reports_after_rna_remove *fastq
```

# SALMON

```{bash, eval=F, echo=T}
gzip /path_to/Trinity_2019filtered_Reference.fasta
```

```{bash, eval=F, echo=T}

/path_to/salmon-latest_linux_x86_64/bin salmon index -t /path_to/Trinity_2019filtered_Reference.fasta.gz -i ref_index_1

```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
echo "Processing sample ${ID}"

# SRR11096631_rna_removed_2_R.fastq
/path_to/salmon quant -i /path_to/ref_index_1 -l A \
         -1 /path_to/${ID}_rna_removed_2_R.fastq \
         -1 /path_to/${ID}_rna_removed_2_R.fastq \
         -p 14 --validateMappings -o ${ID}_quant

done < $FILE
```

output
/mnt4/transciptome_compare/kvach/ncbi/TRANS

ref_index
/mnt4/transciptome_compare/kvach/ncbi/public/ref_trans

fastq
/mnt4/transciptome_compare/kvach/ncbi/public/sra/first_split_try/forward_and_revers_raw_reads/after_trim_galore_1/test_rcorrector_1/FOR_over_rep_remove/after_rna_remove


/home/tools/salmon-latest_linux_x86_64/bin/salmon quant -i /mnt4/transciptome_compare/kvach/ncbi/public/ref_trans/ref_index_1 -l A \
         -1 /mnt4/transciptome_compare/kvach/ncbi/public/sra/first_split_try/forward_and_revers_raw_reads/after_trim_galore_1/test_rcorrector_1/FOR_over_rep_remove/after_rna_remove/SRR11096631_rna_removed_1_F.fastq \
         -2 /mnt4/transciptome_compare/kvach/ncbi/public/sra/first_split_try/forward_and_revers_raw_reads/after_trim_galore_1/test_rcorrector_1/FOR_over_rep_remove/after_rna_remove/SRR11096631_rna_removed_2_R.fastq \
         -p 14 --validateMappings -o SRR11096631_quant
















```{bash, eval=F, echo=T}

```

!!!!!!!!!!!!!!!

!!!!!!!!!!!!!

!!!!!!!!!!!!!!!

!!!!!!!!!!

!!!!!!!!!!!!


!!!!!!!!!!
"In quant.sf we obtained a table of counts, but for each transcript. The counts are fractional numbers. You also have normalized counts (per million reads), and information on the "real" transcript length and an "effective" length that can be used for normalization, which takes into account several biases." 

# EdgeR

## Install packages

We tried to install the required packages using the usual method, but nothing came of it.

```{r}
install.packages("tximport")
install.packages("edgeR")
```


So we found solution there - <https://bioconductor.org/install/>. 

"If" statement is checking if we already had BiocManager package installed, if not then install it. We needed this package to install other bioconductor packages (edgeR, mixOmics, RColorBrewer).


```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
```


For package installation we used function from - <https://stackoverflow.com/a/31620488>. It will check for missing packages and install them + it will query both - CRAN and Bioconductor repositories for missing package.

```{r}
install.packages.auto <- function(x) { 
  x <- as.character(substitute(x)) 
  if(isTRUE(x %in% .packages(all.available=TRUE))) { 
    eval(parse(text = sprintf("require(\"%s\")", x)))
  } else { 
    #update.packages(ask= FALSE) #update installed packages.
    eval(parse(text = sprintf("install.packages(\"%s\", dependencies = TRUE)", x)))
  }
  if(isTRUE(x %in% .packages(all.available=TRUE))) { 
    eval(parse(text = sprintf("require(\"%s\")", x)))
  } else {
    source("http://bioconductor.org/biocLite.R")
    #biocLite(character(), ask=FALSE) #update installed packages.
    eval(parse(text = sprintf("biocLite(\"%s\")", x)))
    eval(parse(text = sprintf("require(\"%s\")", x)))
  }
}
```

Packages installation:

```{r}
install.packages.auto(tximport)
install.packages.auto(edgeR)
install.packages.auto(mixOmics)
install.packages.auto(RColorBrewer)
install.packages.auto(ggplot2)

```

### Troubles with DESeq2 installation for R 3.6.3 

We faced with troubles during installation for R 3.6.3 the DESeq2  package. 

Resolution:

  ```{r}
  if (!requireNamespace("BiocManager", quietly = TRUE))
      BiocManager::install(version = '3.10')
  ```
  
  ```{r}
  BiocManager::install("DESeq2")
  library(DESeq2)
  ```



Library packages:

```{r}
library(tximport)
library(edgeR)
library(mixOmics)
library(RColorBrewer)
library(ggplot2)
library(DESeq2)
```

## Prepairing data 

### Get paths to salmon output for each sample

```{r}
my.files <-  list.files(list.dirs(path = "~/itog_otchet/salmon_quant_output_3", full.names = TRUE, recursive = FALSE), pattern = "quant.sf", full.names = TRUE)
```

As an example, we took 4 samples, with three biological repeats in each:

* budauto - autozooid, bud

  + budauto_29_quant.sf

  + budauto_39_quant.sf

  + budauto_40_quant.sf

* budavic - avicularium, bud

  + budavic_23_quant.sf

  + budavic_24_quant.sf

  + budavic_25_quant.sf

* matauto - autozooid, mature

  + matauto_26_quant.sf

  + matauto_27_quant.sf

  + matauto_28_quant.sf

* matavic - avicularium, mature

  + matavic_22_quant.sf

  + matavic_37_quant.sf

  + matavic_38_quant.sf
  
  
  
  
  
  
  
  rhiauto_34_quant.sf
  
  
  
  
  rhinet_33_quant.sf
  
  
  

```{r}
my.files
```

Each XXXXXX_quant.sf file is a table with 5 colomns. 

* Name - ID of transcripts

* Length - 

* EffectiveLength - 

* TPM - 

* NumReads - Number of reads mapped on this transcript

```{bash, eval=F, echo=T}
cd /path_to/salmon_quant_output/BUD_AUTO_29
head budauto_29_quant.sf 
```


Name	                    |  Length  | 	EffectiveLength	|    TPM	  |  NumReads
--------------------------|----------|------------------|-----------|-------
TRINITY_DN174516_c0_g1_i1 | 	 215   |    	68.774	    |  0.000000	|    0.000
TRINITY_DN174582_c0_g1_i1	|    289	 |      132.312	    |  0.000000	|    0.000
TRINITY_DN174551_c0_g1_i1	|    238	 |      87.409	    |  0.000000	|    0.000
TRINITY_DN174560_c0_g1_i1	|    209	 |      64.123	    |  0.000000	|    0.000
TRINITY_DN174581_c0_g1_i1	|    263	 |      108.553	    |  0.000000	|    0.000
TRINITY_DN174540_c0_g1_i1	|    229	 |      80.031	    |  1.651575	|    1.000
TRINITY_DN174596_c0_g1_i1	|    214	 |      67.978	    |  0.000000	|    0.000
TRINITY_DN174531_c0_g1_i1	|    436	 |      275.061 	  |  0.000000	|    0.000
TRINITY_DN174511_c0_g1_i1	|    239	 |      88.249	    |  0.000000	|    0.000


### Create object - readeDGE 

We created file of a readDGE class from our quant.sf-files. 5 columns were took + we add a group for each sample (one sample - one number).

```{r}
tab <- readDGE(files = my.files, columns = c(1, 5), group = c(1,1,1, 2,2,2, 3,3,3, 4,4,4, 5,5,5, 6,6,6))  
```

Checked our file:

```{r, eval=F, echo=T}
head(tab, 10)
```
## Filtering

We have filtered out low expression transcripts. 

filterByExpr() - this function determine which transcripts have sufficiently large counts to be retained in a statistical analysis.

Chen Y, Lun ATL, and Smyth, GK (2016). From reads to genes to pathways: differential expression analysis of RNA-Seq experiments using Rsubread and the edgeR quasi-likelihood pipeline. F1000Research 5, 1438. http://f1000research.com/articles/5-1438

```{r}
keep <- filterByExpr(tab)
table(keep)
```

```{r}
tab_filtered <- tab[keep, , keep.lib.sizes = FALSE]
```

```{r, eval=F, echo=T}
head(tab_filtered, 10)
```
## Effective library sizes

calcNormFactors() - this function calculate normalization factors to scale the raw library sizes that minimizes the log-fold changes between the samples for most transcripts.

```{r}
tab_filt_norm <- calcNormFactors(tab_filtered) 
head(tab_filt_norm$samples)
```

### PcoA (MDS plot)

"The function plotMDS produces a plot in which distances between samples correspond to leading biological coefficient of variation (BCV) between those samples:"
```{r}
sample_names = c("Bud_auto_29", "Bud_auto_39", "Bud_auto_40", "Bud_avic_23", "Bud_avic_24", "Bud_avic_25", "Mat_auto_26", "Mat_auto_27", "Mat_auto_28", "Mat_avic_22", "Mat_avic_37", "Mat_avic_38", "RHI_AUTO_34", "RHI_AUTO_35", "RHI_AUTO_36", "RHI_NET_31", "RHI_NET_32", "RHI_NET_33")

plotMDS(tab_filt_norm, col=rep(1:6, each=3), labels = sample_names)
```

## Estimating dispersions


<https://bioinformatics.cvr.ac.uk/some-key-factors-for-number-of-significant-de-genes/#:~:text=The%20BCV%20(Biological%20Coefficient%20of,could%20detect%20more%20DE%20genes.>


Biological coefficient of variation

An important factor that influences the number of DE genes is the variation among the samples.The BCV (Biological Coefficient of Variation) plot is a way to measure the biological variation within a particular condition. A common dispersion (i.e. red line on the BCV plot) between 0.2 and 0.4 is usually considered reasonable and hence could detect more DE genes.If the common dispersion is above the 0.4 threshold, this will influence the number of DE genes found in the study. Additionally, the PCA (principal component analysis) and MDS (multidimensional scaling) plots which represents the relationship between groups of samples are affected by high BCVs. The experiment was run twice. We can see the differences in the BCV and MDS plots between the two experiments. An experiment where the common dispersion is 0.41 provides almost 576 DE genes whilst an experiment with high average BCV results in only 109 DE genes. Additionally, the MDS plots clearly differentiate the different conditions when the common dispersion is low implying greater variation between the conditions than within, as expected.


### no design


```{r}
tab_de_3 <- estimateDisp(tab_filt_norm)
tab_de_3
```



```{r}
plotBCV(tab_de_3)
# plotBCV(tab_de_3, col.tagwise = metadata$age)
```

### with design

```{r}
sample_names = c("Bud_auto_29", "Bud_auto_39", "Bud_auto_40", "Bud_avic_23", "Bud_avic_24", "Bud_avic_25", "Mat_auto_26", "Mat_auto_27", "Mat_auto_28", "Mat_avic_22", "Mat_avic_37", "Mat_avic_38", "RHI_AUTO_34", "RHI_AUTO_35", "RHI_AUTO_36", "RHI_NET_31", "RHI_NET_32", "RHI_NET_33")

zooid_type <- c('AU','AU','AU', 'av', 'av', 'av','AU','AU','AU', 'av', 'av', 'av', 'rhi', 'rhi', 'rhi', 'rhi', 'rhi', 'rhi')

age <- c('b', 'b', 'b', 'b', 'b', 'b', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M', 'M')

all_against_all <- c(1:18)

each_sample <- c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6)

metadata <- data.frame(sample_names, zooid_type, age, all_against_all, each_sample)
metadata
```

#### ~zooid_type

```{r}
design_zt <- model.matrix(~zooid_type, data = metadata)
rownames(design_zt) <- sample_names
design_zt
```

```{r}
tab_zt <- estimateDisp(tab_filt_norm, design_zt, robust=TRUE)
tab_zt
```

```{r}
plotBCV(tab_zt)
```


#### ~age

```{r}
design_age <- model.matrix(~age, data = metadata)
rownames(design_age) <- sample_names
design_age
```

```{r}
tab_age <- estimateDisp(tab_filt_norm, design_age, robust=TRUE)
tab_age
```

```{r}
plotBCV(tab_age)
```


#### ~all_against_all

```{r}
design_all_against_all <- model.matrix(~all_against_all, data = metadata)
rownames(design_all_against_all) <- sample_names
design_all_against_all
```

```{r}
tab_all_against_all <- estimateDisp(tab_filt_norm, design_all_against_all, robust=TRUE)
tab_all_against_all
```


```{r}
plotBCV(tab_all_against_all)
```



#### ~age + zooide type

```{r}
design_age_zooide_type<- model.matrix(~age + zooid_type, data = metadata)
rownames(design_age_zooide_type) <- sample_names
design_age_zooide_type
```

```{r}
tab_age_zooide_type <- estimateDisp(tab_filt_norm, design_age_zooide_type, robust=TRUE)
tab_age_zooide_type
```


```{r}
plotBCV(tab_age_zooide_type)
```



#### ~each_sample

```{r}
design_each_sample<- model.matrix(~each_sample, data = metadata)
rownames(design_each_sample) <- sample_names
design_each_sample
```

```{r}
tab_each_sample<- estimateDisp(tab_filt_norm, design_each_sample, robust=TRUE)
tab_each_sample
```


```{r}
plotBCV(tab_each_sample, col.tagwise = metadata$each_sample)
```




#### ~each_sample

```{r}
design_each_sample_age_zooid<- model.matrix(~each_sample + age + zooid_type + all_against_all, data = metadata)
rownames(design_each_sample_age_zooid) <- sample_names
design_each_sample_age_zooid
```

```{r}
tab_each_sample_age_zooid<- estimateDisp(tab_filt_norm, design_each_sample_age_zooid, robust=TRUE)
tab_each_sample_age_zooid
```

```{r}
plotBCV(tab_each_sample_age_zooid, col.tagwise = metadata$each_sample)
```

















### PCA



```{r}
## Transform count data
rld <- rlog(tab_de_3)

## Perform PCA analysis and make plot
plotPCA(rld)
```










### compre

```{r}
tab_de_3$common.dispersion 
tab_zt$common.dispersion 
tab_age$common.dispersion 
tab_all_against_all$common.dispersion
tab_each_sample$common.dispersion
```









































### ?





qlf.2vs1 <- glmQLFTest(fit, coef = 2:4)
z <- topTags(qlf.2vs1, n = 30)
head(z)

z_table <- z$table

logcpm <- cpm(tab3, log=TRUE)
logcpm




# References

Bowtie2 - <http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#output-options>

FastQC - 

MultiQC - <https://multiqc.info/>

SALMON - 

Sratoolkit - <http://ncbi.github.io/sra-tools/>

TrimGalore-0.6.6 - 

