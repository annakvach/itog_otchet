---
title: "i_4"
author: "anna kvach"
date: "12/16/2020"
output:
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 4
    theme: united
    highlight: tango
  pdf_document:
    toc: yes
    toc_depth: '4'
---

# Introduction

# Obtain data

For or work needed forward and reverse reads and transcriptome assembly and annotation for it.

We used Autozooid-Avicularium Transcriptome, Annotation  for it and reads (includes autozooid bud, mature autozooid, avicularium bud, and mature avicularium samples) of Bugulina stolonifera 

## Transcriptome assembly and annotation

Transcriptome assembly - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDJZ4X> - Autozooid-Avicularium Transcriptome (includes autozooid bud, mature autozooid, avicularium bud, and mature avicularium samples) of Bugulina stolonifera 

```{bash, eval=F, echo=T}
mkdir Transcriptome_assembly
cd Transcriptome_assembly
wget https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/U3DI0X

mv ':persistentId?persistentId=doi:10.7910%2FDVN%2FSDJZ4X%2FU3DI0X' Tr_assem.fasta # rename to the file with .fasta formate

```

Transcriptome annotation - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GHE8T4> - Autozooid Bud, Mature Autozooid, Avicularium Bud, and Mature Avicularium Transcriptome Annotation Report

```{bash, eval=F, echo=T}
mkdir Transcriptome_annotation
cd Transcriptome_annotation
wget https://dataverse.harvard.edu/api/access/datafile/4005816

mv 4005816 tr_annot.xls # rename to the file with .xls formate
```

```{bash, eval=F, echo=T}
mkdir transcriptome_assembly
wget -P transcriptome_assembly https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/RXE6CF
```


## PE


Zooid type          |    SRR ID        | 
--------------------|------------------|
avicularium, mature | 	 SRR11096622   |    
avicularium, bud	  |    SRR11096623	 |  
avicularium, bud  	|    SRR11096624	 |     
avicularium, bud  	|    SRR11096625	 |    
autozooid, mature	  |    SRR11096626	 |      
autozooid, mature	  |    SRR11096627	 |      
autozooid, mature	  |    SRR11096628	 |     
autozooid, bud	    |    SRR11096629	 |   
avicularium, mature |    SRR11096637	 |     
avicularium, mature |    SRR11096638	 | 
autozooid, bud	    |    SRR11096639	 |     
autozooid, bud	    |    SRR11096640	 | 


There are two options how to obtain reads-data: with help of Sratoolkit and simple bash code or manually from EBLM-EBI. 

### Sratoolkit + simple bash 

Using this method, we created a simple bash program that receives a file.txt with sra identifiers as input. Our code uses the prefetch and fastq-dump programs from the Sratoolkit package, and as a result downloads forward and backward reads.


First of all we created a file.txt with all sra id on each line. We used this file each time we needed to iteratete by .fastq files

```{bash, eval=F, echo=T}
vi id.txt
```

```{bash, content of txt.file, eval=F, echo=T}
SRR11096622
SRR11096623
SRR11096624  
SRR11096625
SRR11096626
SRR11096627
SRR11096628
SRR11096629
SRR11096637
SRR11096638
SRR11096639
SRR11096640
```

After that sra_dowload_with_sratoolkit.sh was create.  

```{bash, sra_dowload_with_sratoolkit, eval=F, echo=T}
#!/bin/bash  
# for SRA files downloading with help of sratoolkit                                           
FILE=$1                            
while read id                      
do                                 
prefetch $id                       
echo "for $id prefetch done"       
fastq-dump --split-files --split-3 ${id}.sra
echo "for $id fastq-dump done"     
done < $FILE
```

And after that:

```{bash, eval=F, echo=T}
/path_to/sra_dowload_with_sratoolkit.sh sra_id.txt
```

In result you got for all samples SRRXXXXXXXX_1.fastq.gz (forward reads) and (revers reads) SRRXXXXXXXX_2.fastq.gz, and for some samples - SRRXXXXXXXX.fastq.gz - files without prefix. Files with no prefix are files of the remaining unpaired reads, and we did not use them.

```{bash, eval=F, echo=T}
mkdir /path_to/forward_and_revers_raw_reads # create dir for forward and revers raw reads
mkdir /path_to/bad_single_reads # create dir for unpaired reads

mv *_*.*  /path_to/forward_and_revers_raw_reads # dir for forward and revers raw reads - data for future analisis
mv *.f* /path_to/bad_single_reads # dir for remaining unpaired reads - did not use them
```


### Directly and manually from EBLM-EBI

Also data could be obtained directly and manually from EBLM-EBI - <https://www.ebi.ac.uk/ena/browser/view/PRJNA607082>. 

Files with forward reads have "_1" prefix (for ex. SRR11096622_1.fastq.gz) and files with reverse reads have "_2" prefix (for ex. SRR11096622_2.fastq.gz). Files with no prefix are files of the remaining unpaired reads, and we did not need them.


# First data quality assessment FastQC and MultiQC

## FastQC_1

```{bash, eval=F, echo=T}

# start to work with good paired reads
cd forward_and_revers_raw_reads 

# to unarchive all data  
gunzip *fastq.gz 

# create new dir for fastqc reports
mkdir /path_to/FastQC_1_for_raw_data 

# create fastqc reports in FastQC_1_for_raw_data
fastqc -t 10 -o /path_to/FastQC_1_for_raw_data * 
```

## MultiQC_1

```{bash, eval=F, echo=T}
# to summarising the output from numerous fastqc reports in one .html file
multiqc /path_to/FastQC_1_for_raw_data
```

Quality reports show problems with:

* 

* 

# Trim Galore + second FastQC after it

As we faced with adapters-problem we create file.fasta with adapters from <http://docs.blast2go.com/user-manual/tools-(pro-feature)/fastq-quality-check/#FASTQQualityCheck-PerBaseSequenceQuality>.


```{bash, eval=F, echo=T}
vi adapters.fasta
```

```{bash, eval=F, echo=T}
>Illumina_Universal_Adapter 
AGATCGGAAGAG
>Illumina_Small_RNA_3_Adapter
TGGAATTCTCGG
>Illumina_Small_RNA_5_Adapter
GATCGTCGGACT
```


```{bash, eval=F, echo=T}
#####
#!/bin/bash  
# for trimming with TrimGalore for forward and reverse reads                                           
FILE=$1                            
while read id                      
do                                     
/path_to/TrimGalore-0.6.6/trim_galore --paired --phred33 -q 20 --length 36 -stringency 1 -e 0.1 -a2 "file:/path_to/adapters.fasta" -o after_trim_galore_1  --fastqc ${id}_1.fastq ${id}_2.fastq 
echo "for $id fastq-dump done --split-3"     
done < $FILE
```

* -q 20 - remove low-quality reads with a Phred score cutoff of 20

* --length 36 - a minimum read length threshold of 36 bp

* -stringency 1 - a stringency parameter of 1 for adapter sequence overlap

* -e 0.1 - a maximum allowed error rate of (0.1) 

* -a2 "file:/path_to/adapters.fasta" - to specify individual adapter sequences from our file.fasta for the two reads of paired-end files

* -o after_trim_galore_1  - all output will be written to this directory 

* --fastqc - create fastQC report

* {$1}_1.fastq - forward reads 

* {$id}_2.fastq - reverse reads 

## MultiQC_2

```{bash, eval=F, echo=T}
multiqc /path_to/after_trim_galore_1
```

Quality reports show problems with:

* 

* 

# Rcorrector

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

/home/tools/rcorrector -p SRR11096622_1_val_1.fq SRR11096622_2_val_2.fq -p SRR11096623_1_val_1.fq SRR11096623_2_val_2.fq -od test_rcorrector_1


## MultiQC_3
```{bash, eval=F, echo=T}
multiqc /path_to/test_rcorrector_1
```


# Identify and remove over-represented sequences

Based on all FastQC reports table () and .fasta file (over_r_rRNA.fasta) with all over-represented sequences was created. 

Using over_r_rRNA.fasta with help of Blastn - (<https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome>) all unique sequences were identified.

* Database --> Standard databases (nr/nt) --> Nucleotide collection (nr/nt)

* Organism --> bryozoans (taxid:10205)

After that, it was indicated in the table opposite each sequence what it encodes.

## Bowtie2 - Remove over-represented sequences 

The example we used to complete this part. - <https://sites.google.com/site/wiki4metagenomics/tools/short-read/remove-host-sequences>

Bowtie2 database was created using fasta file with over-represented sequences.

```{bash, eval=F, echo=T}
bowtie2-build over_r_rRNA.fasta O_R_rRNA_DB
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        bowtie2 -p 14 -x /path_to/O_R_rRNA_DB \
        -1 /path_to/${ID}_1_val_1.cor.fq \
        -2 /path_to/${ID}_2_val_2.cor.fq \
        --un-conc /path_to/${ID}_rna_removed > ${ID}mapped_and_unmapped.sam

done < $FILE

```


```{bash, eval=F, echo=T}
/path_to/code_to_remove_o_r_rrna.sh id.txt
```





```{bash, eval=F, echo=T}
mkdir after_rna_remove 
cp id.txt ./after_rna_remove/id_1.txt
mv *_rna_removed* after_rna_remove 
```


```{bash, eval=F, echo=T}
vi for_rename.sh
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        mv ${ID}_rna_removed.1 ${ID}_rna_removed_1_F.fastq
        mv ${ID}_rna_removed.2 ${ID}_rna_removed_2_R.fastq

done < $FILE

```

```{bash, eval=F, echo=T}
chmod +x for_rename.sh
```

```{bash, eval=F, echo=T}
mkdir fastq_reports_after_rna_remove
fastqc -o fastq_reports_after_rna_remove *fastq
```



# SALMON

```{bash, eval=F, echo=T}
gzip Tr_assem.fasta
```

```{bash, eval=F, echo=T}

cd /path_to/Transcriptome_assembly

/path_to/salmon-latest_linux_x86_64/bin/salmon index -t Tr_assem.fasta.gz -i ref_index_Tr_assem

```


```{bash}
vi for_salmon_quant.sh
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
echo "Processing sample ${ID}"

# SRR11096631_rna_removed_2_R.fastq
/path_to/salmon quant -i /path_to/ref_index_Tr_assem -l A \
         -1 /path_to/${ID}_rna_removed_1_F.fastq \
         -2 /path_to/${ID}_rna_removed_2_R.fastq \
         -p 14 --validateMappings -o ${ID}_quant

done < $FILE
```

















```{bash, eval=F, echo=T}

```

!!!!!!!!!!!!!!!

!!!!!!!!!!!!!

!!!!!!!!!!!!!!!

!!!!!!!!!!

!!!!!!!!!!!!


!!!!!!!!!!
"In quant.sf we obtained a table of counts, but for each transcript. The counts are fractional numbers. You also have normalized counts (per million reads), and information on the "real" transcript length and an "effective" length that can be used for normalization, which takes into account several biases." 
