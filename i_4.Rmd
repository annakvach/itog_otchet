---
title: "i_4"
author: "anna kvach"
date: "12/16/2020"
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 4
    theme: united
    highlight: tango
---

# Introduction

# Obtain data

For or work needed forward and reverse reads and transcriptome assembly and annotation for it.

## Transcriptome assembly and annotation

Transcriptome assembly - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDJZ4X> - Autozooid-Avicularium Transcriptome (includes autozooid bud, mature autozooid, avicularium bud, and mature avicularium samples) of Bugulina stolonifera 

```{bash}

```

Transcriptome annotation - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GHE8T4> - Autozooid Bud, Mature Autozooid, Avicularium Bud, and Mature Avicularium Transcriptome Annotation Report

```{bash}

```



## PE

```{bash, eval=F, echo=T}
mkdir transcriptome_assembly
wget -P transcriptome_assembly https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/RXE6CF
```

There are two options how to obtain reads-data: with help of Sratoolkit and simple bash code or manually from EBLM-EBI. 

### Sratoolkit + simple bash 

Using this method, we created a simple bash program that receives a file.txt with sra identifiers as input. Our code uses the prefetch and fastq-dump programs from the Sratoolkit package, and as a result downloads forward and backward reads.


First of all we created a file.txt with all sra id on each line.

```{bash, eval=F, echo=T}
vi id.txt
```

```{bash, content of txt.file, eval=F, echo=T}
SRR11096622
SRR11096623
SRR11096624
SRR11096625
SRR11096626
SRR11096627
SRR11096628
SRR11096629
SRR11096630
SRR11096631
SRR11096632
SRR11096633
SRR11096634
SRR11096635
SRR11096636
SRR11096637
SRR11096638
SRR11096639
SRR11096640
```

After that sra_dowload_with_sratoolkit.sh was create.  

```{bash, sra_dowload_with_sratoolkit, eval=F, echo=T}
#!/bin/bash  
# for SRA files downloading with help of sratoolkit                                           
FILE=$1                            
while read id                      
do                                 
prefetch $id                       
echo "for $id prefetch done"       
fastq-dump --split-files --split-3 ${id}.sra
echo "for $id fastq-dump done"     
done < $FILE
```

And after that:

```{bash, eval=F, echo=T}
/path_to/sra_dowload_with_sratoolkit.sh sra_id.txt
```

In result you got for all samples SRRXXXXXXXX_1.fastq.gz (forward reads) and (revers reads) SRRXXXXXXXX_2.fastq.gz, and for some samples - SRRXXXXXXXX.fastq.gz - files without prefix. Files with no prefix are files of the remaining unpaired reads, and we did not use them.

```{bash, eval=F, echo=T}
mkdir /path_to/forward_and_revers_raw_reads # create dir for forward and revers raw reads
mkdir /path_to/bad_single_reads # create dir for unpaired reads

mv *_*.*  /path_to/forward_and_revers_raw_reads # dir for forward and revers raw reads - data for future analisis
mv *.f* /path_to/bad_single_reads # dir for remaining unpaired reads - did not use them
```


### Directly and manually from EBLM-EBI

Also data could be obtained directly and manually from EBLM-EBI - <https://www.ebi.ac.uk/ena/browser/view/PRJNA607082>. 

Files with forward reads have "_1" prefix (for ex. SRR11096622_1.fastq.gz) and files with reverse reads have "_2" prefix (for ex. SRR11096622_2.fastq.gz). Files with no prefix are files of the remaining unpaired reads, and we did not need them.


# First data quality assessment FastQC and MultiQC

## FastQC_1

```{bash, eval=F, echo=T}

# start to work with good paired reads
cd forward_and_revers_raw_reads 

# to unarchive all data  
gunzip *fastq.gz 

# create new dir for fastqc reports
mkdir /path_to/FastQC_1_for_raw_data 

# create fastqc reports in FastQC_1_for_raw_data
fastqc -t 10 -o /path_to/FastQC_1_for_raw_data * 
```

## MultiQC_1

```{bash, eval=F, echo=T}
# to summarising the output from numerous fastqc reports in one .html file
multiqc /path_to/FastQC_1_for_raw_data
```

Quality reports show problems with:

* 

* 

# Trim Galore + second FastQC after it

As we faced with adapters-problem we create file.fasta with adapters from <http://docs.blast2go.com/user-manual/tools-(pro-feature)/fastq-quality-check/#FASTQQualityCheck-PerBaseSequenceQuality>.


```{bash, eval=F, echo=T}
vi adapters.fasta
```

```{bash, eval=F, echo=T}
>Illumina_Universal_Adapter 
AGATCGGAAGAG
>Illumina_Small_RNA_3_Adapter
TGGAATTCTCGG
>Illumina_Small_RNA_5_Adapter
GATCGTCGGACT
```


```{bash, eval=F, echo=T}
#####
#!/bin/bash  
# for trimming with TrimGalore for forward and reverse reads                                           
FILE=$1                            
while read id                      
do                                     
/path_to/TrimGalore-0.6.6/trim_galore --paired --phred33 -q 20 --length 36 -stringency 1 -e 0.1 -a2 "file:/path_to/adapters.fasta" -o after_trim_galore_1  --fastqc ${id}_1.fastq ${id}_2.fastq 
echo "for $id fastq-dump done --split-3"     
done < $FILE
```

* -q 20 - remove low-quality reads with a Phred score cutoff of 20

* --length 36 - a minimum read length threshold of 36 bp

* -stringency 1 - a stringency parameter of 1 for adapter sequence overlap

* -e 0.1 - a maximum allowed error rate of (0.1) 

* -a2 "file:/path_to/adapters.fasta" - to specify individual adapter sequences from our file.fasta for the two reads of paired-end files

* -o after_trim_galore_1  - all output will be written to this directory 

* --fastqc - create fastQC report

* {$1}_1.fastq - forward reads 

* {$id}_2.fastq - reverse reads 

## MultiQC_2

```{bash, eval=F, echo=T}
multiqc /path_to/after_trim_galore_1
```

Quality reports show problems with:

* 

* 

# Rcorrector

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```

/home/tools/rcorrector -p SRR11096622_1_val_1.fq SRR11096622_2_val_2.fq -p SRR11096623_1_val_1.fq SRR11096623_2_val_2.fq -od test_rcorrector_1


## MultiQC_3
```{bash, eval=F, echo=T}
multiqc /path_to/test_rcorrector_1
```


# Identify and remove over-represented sequences

Based on all FastQC reports table () and .fasta file (over_r_rRNA.fasta) with all over-represented sequences was created. 

Using over_r_rRNA.fasta with help of Blastn - (<https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome>) all unique sequences were identified.

* Database --> Standard databases (nr/nt) --> Nucleotide collection (nr/nt)

* Organism --> bryozoans (taxid:10205)

After that, it was indicated in the table opposite each sequence what it encodes.

## Bowtie2 - Remove over-represented sequences 

The example we used to complete this part. - <https://sites.google.com/site/wiki4metagenomics/tools/short-read/remove-host-sequences>

Bowtie2 database was created using fasta file with over-represented sequences.

```{bash, eval=F, echo=T}
bowtie2-build over_r_rRNA.fasta O_R_rRNA_DB
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        bowtie2 -p 14 -x /path_to/O_R_rRNA_DB \
        -1 /path_to/${ID}_1_val_1.cor.fq \
        -2 /path_to/${ID}_2_val_2.cor.fq \
        --un-conc /path_to/${ID}_rna_removed > ${ID}mapped_and_unmapped.sam

done < $FILE

```


```{bash, eval=F, echo=T}
/path_to/code_to_remove_o_r_rrna.sh id.txt
```





```{bash, eval=F, echo=T}
mkdir after_rna_remove 
cp id.txt ./after_rna_remove/id_1.txt
mv *_rna_removed* after_rna_remove 
```


```{bash, eval=F, echo=T}
vi for_rename.sh
```

```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        mv ${ID}_rna_removed.1 ${ID}_rna_removed_1_F.fastq
        mv ${ID}_rna_removed.2 ${ID}_rna_removed_2_R.fastq

done < $FILE

```

```{bash, eval=F, echo=T}
chmod +x for_rename.sh
```

```{bash, eval=F, echo=T}
mkdir fastq_reports_after_rna_remove
fastqc -o fastq_reports_after_rna_remove *fastq
```



