---
title: "Autozooid-Avicularium Transcriptome"
author: "anna kvach"
date: "12/16/2020"
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  html_document:
    toc: yes
    number_sections: yes
    toc_depth: 4
    theme: united
    highlight: tango
---

# Introduction

# Obtain data


For or work needed forward and reverse reads and transcriptome assembly and annotation for it.

We used Autozooid-Avicularium Transcriptome, Annotation  for it and reads (includes autozooid bud, mature autozooid, avicularium bud, and mature avicularium samples) of Bugulina stolonifera 


## Transcriptome assembly and annotation



Transcriptome assembly - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/SDJZ4X> - Autozooid-Avicularium Transcriptome (includes autozooid bud, mature autozooid, avicularium bud, and mature avicularium samples) of Bugulina stolonifera 



```{bash, eval=F, echo=T}

# mkdir Transcriptome_assembly
# cd Transcriptome_assembly
# wget https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/U3DI0X

# mv ':persistentId?persistentId=doi:10.7910%2FDVN%2FSDJZ4X%2FU3DI0X' Tr_assem.fasta # rename to the file with .fasta formate

```



Transcriptome annotation - <https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/GHE8T4> - Autozooid Bud, Autozooid Mature, Avicularium Bud, Avicularium Mature  Transcriptome Annotation Report



```{bash, eval=F, echo=T}
mkdir Transcriptome_annotation
cd Transcriptome_annotation
wget https://dataverse.harvard.edu/api/access/datafile/4005816

mv 4005816 tr_annot.xls # rename to the file with .xls formate
```



```{bash, eval=F, echo=T}
mkdir transcriptome_assembly
wget -P transcriptome_assembly https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/SDJZ4X/RXE6CF
```



## PE



Zooid type          |    SRR ID        | 
--------------------|------------------|
avicularium, mature | 	 SRR11096622   |    
avicularium, bud	  |    SRR11096623	 |  
avicularium, bud  	|    SRR11096624	 |     
avicularium, bud  	|    SRR11096625	 |    
autozooid, mature	  |    SRR11096626	 |      
autozooid, mature	  |    SRR11096627	 |      
autozooid, mature	  |    SRR11096628	 |     
autozooid, bud	    |    SRR11096629	 |   
avicularium, mature |    SRR11096637	 |     
avicularium, mature |    SRR11096638	 | 
autozooid, bud	    |    SRR11096639	 |     
autozooid, bud	    |    SRR11096640	 | 



There are two options how to obtain reads-data: with help of Sratoolkit and simple bash code or manually from EBLM-EBI. 



### Sratoolkit + simple bash 



Using this method, we created a simple bash program that receives a file.txt with sra identifiers as input. Our code uses the prefetch and fastq-dump programs from the Sratoolkit package, and as a result downloads forward and backward reads.



First of all we created a id.txt with all sra id on each line. We used this file each time we needed to iteratete by .fastq files



```{bash, eval=F, echo=T}
vi id.txt
```



```{bash, content of txt.file, eval=F, echo=T}
SRR11096622
SRR11096623
SRR11096624  
SRR11096625
SRR11096626
SRR11096627
SRR11096628
SRR11096629
SRR11096637
SRR11096638
SRR11096639
SRR11096640
```



And we used simple bash code to do the operation for each pair of reads: 



```{bash, sra_dowload_with_sratoolkit, eval=F, echo=T}
#!/bin/bash  
# for SRA files downloading with help of sratoolkit                                           
FILE=$1                            
while read id                      
do                                 
prefetch $id                       
echo "for $id prefetch done"       
fastq-dump --split-files --split-3 ${id}.sra
echo "for $id fastq-dump done"     
done < $FILE
```



And after that:



```{bash, eval=F, echo=T}
/path_to/sra_dowload_with_sratoolkit.sh sra_id.txt
```



In result you got for all samples SRRXXXXXXXX_1.fastq.gz (forward reads) and (revers reads) SRRXXXXXXXX_2.fastq.gz, and for some samples - SRRXXXXXXXX.fastq.gz - files without prefix. Files with no prefix are files of the remaining unpaired reads, and we did not use them.



```{bash, eval=F, echo=T}
mkdir /path_to/forward_and_revers_raw_reads # create dir for forward and revers raw reads
mkdir /path_to/bad_single_reads # create dir for unpaired reads

mv *_*.*  /path_to/forward_and_revers_raw_reads # dir for forward and revers raw reads 
mv *.f* /path_to/bad_single_reads # dir for remaining unpaired reads - did not use them
```



### Directly and manually from EBLM-EBI



Also data could be obtained directly and manually from EBLM-EBI - <https://www.ebi.ac.uk/ena/browser/view/PRJNA607082>. 

Files with forward reads have "_1" prefix (for ex. SRR11096622_1.fastq.gz) and files with reverse reads have "_2" prefix (for ex. SRR11096622_2.fastq.gz). Files with no prefix are files of the remaining unpaired reads, and we did not need them.



# First data quality assessment FastQC and MultiQC



## FastQC_1



```{bash, eval=F, echo=T}

# start to work with good paired reads
cd forward_and_revers_raw_reads 

# to unarchive all data  
gunzip *fastq.gz 

# create new dir for fastqc reports
mkdir /path_to/FastQC_1_for_raw_data 

# create fastqc reports in FastQC_1_for_raw_data
fastqc -t 10 -o /path_to/FastQC_1_for_raw_data * 
```




## MultiQC_1



```{bash, eval=F, echo=T}
# to summarising the output from numerous fastqc reports in one .html file
multiqc /path_to/FastQC_1_for_raw_data
```




Quality reports show problems with:

* The mean quality value across each base position in the read for 4 fastq files

* The proportion of each base position for which each of the four normal DNA bases has been called for all

* Per Sequence GC Content for all

* Sequence Duplication Levels for all

* Overrepresented sequences for 23 fastq files is failed

* Adapter Content for all



You can find my quality report in repository - multiqc_report_RAW_READS.html



# Trim Galore + second FastQC after it



As we faced with adapters-problem we create file.fasta with adapters from <http://docs.blast2go.com/user-manual/tools-(pro-feature)/fastq-quality-check/#FASTQQualityCheck-PerBaseSequenceQuality>.




```{bash, eval=F, echo=T}
vi adapters.fasta
```



```{bash, eval=F, echo=T}
>Illumina_Universal_Adapter 
AGATCGGAAGAG
>Illumina_Small_RNA_3_Adapter
TGGAATTCTCGG
>Illumina_Small_RNA_5_Adapter
GATCGTCGGACT
```



And we used default options (as it was pointed in the papper) for Trim Galore:



* -q 20 - remove low-quality reads with a Phred score cutoff of 20

* --length 36 - a minimum read length threshold of 36 bp

* -stringency 1 - a stringency parameter of 1 for adapter sequence overlap

* -e 0.1 - a maximum allowed error rate of (0.1) 

* -a2 "file:/path_to/adapters.fasta" - to specify individual adapter sequences from our file.fasta for the two reads of paired-end files

* -o after_trim_galore_1  - all output will be written to this directory 

* --fastqc - create fastQC report

* {$1}_1.fastq - forward reads 

* {$id}_2.fastq - reverse reads 



```{bash, eval=F, echo=T}
#####
#!/bin/bash  
# for trimming with TrimGalore for forward and reverse reads                                           
FILE=$1                            
while read id                      
do                                     
/path_to/TrimGalore-0.6.6/trim_galore --paired --phred33 -q 20 --length 36 -stringency 1 -e 0.1 -a2 "file:/path_to/adapters.fasta" -o after_trim_galore_1  --fastqc ${id}_1.fastq ${id}_2.fastq 
echo "for $id fastq-dump done --split-3"     
done < $FILE
```



## MultiQC_2



```{bash, eval=F, echo=T}
multiqc /path_to/after_trim_galore_1
```



Quality reports steel show problems with:

* The proportion of each base position for which each of the four normal DNA bases has been called for all

* Per Sequence GC Content became a little bit better

* Sequence Duplication Levels for all

* Overrepresented sequences became a little bit better

You can find my quality report in repository - multiqc_report_TRIM_GALORE.html



# Rcorrector



```{bash, eval=F, echo=T}
mkdir /path_to/test_rcorrector_1
```



```{bash, eval=F, echo=T}
/path_to/rcorrector -p SRR11096623_1_val_1.fq SRR11096623_2_val_2.fq \
-p SRR11096624_1_val_1.fq SRR11096624_2_val_2.fq \
-p SRR11096625_1_val_1.fq SRR11096625_2_val_2.fq \
-p SRR11096637_1_val_1.fq SRR11096637_2_val_2.fq \
-p SRR11096638_1_val_1.fq SRR11096638_2_val_2.fq \
-p SRR11096622_1_val_1.fq SRR11096622_2_val_2.fq \
-p SRR11096629_1_val_1.fq SRR11096629_2_val_2.fq \
-p SRR11096639_1_val_1.fq SRR11096639_2_val_2.fq \
-p SRR11096640_1_val_1.fq SRR11096640_2_val_2.fq \
-p SRR11096626_1_val_1.fq SRR11096626_2_val_2.fq \
-p SRR11096627_1_val_1.fq SRR11096627_2_val_2.fq \
-p SRR11096628_1_val_1.fq SRR11096628_2_val_2.fq -od test_rcorrector_1
```



## MultiQC_3
```{bash, eval=F, echo=T}
multiqc /path_to/test_rcorrector_1
```


Quality report does not change.

You can find my quality report in repository - multiqc_report_RCORRECTOR.html



# Identify and remove over-represented sequences



Based on all FastQC reports table () and .fasta file (over_r_rRNA.fasta) with all over-represented sequences was created. 

You can find table_FastQC_reports.csv and .fasta file (over_r_rRNA.fasta).



Using over_r_rRNA.fasta with help of Blastn - (<https://blast.ncbi.nlm.nih.gov/Blast.cgi?PROGRAM=blastn&PAGE_TYPE=BlastSearch&LINK_LOC=blasthome>) all unique sequences were identified.

* Database --> Standard databases (nr/nt) --> Nucleotide collection (nr/nt)

* Organism --> bryozoans (taxid:10205)



After that, it was indicated in the table opposite each sequence what it encodes. 

The sequences of ribosomal RNA and cytochrome oxidases were transferred to the fast file (over_r_rRNA.fasta). 

This is necessary for the next cleaning step.



## Bowtie2 - Remove over-represented sequences 



We used Bowtie2 to filtered the read, which mapped on over_r_rRNA.fasta (file with rRNA and COI sequences). 

The example we used to complete this part. - <https://sites.google.com/site/wiki4metagenomics/tools/short-read/remove-host-sequences>

Bowtie2 database was created using fasta file with over-represented sequences.



```{bash, eval=F, echo=T}
bowtie2-build over_r_rRNA.fasta O_R_rRNA_DB
```



And we used simple bash code to do the operation for each pair of reads:



```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        bowtie2 -p 14 -x /path_to/O_R_rRNA_DB \
        -1 /path_to/${ID}_1_val_1.cor.fq \
        -2 /path_to/${ID}_2_val_2.cor.fq \
        --un-conc /path_to/${ID}_rna_removed > ${ID}mapped_and_unmapped.sam

done < $FILE

```



```{bash, eval=F, echo=T}
chmod +x code_to_remove_o_r_rrna.sh
```



Run code:



```{bash, eval=F, echo=T}
/path_to/code_to_remove_o_r_rrna.sh id.txt
```



The otput file loks like {ID}_rna_removed.1 and {ID}_rna_removed.2, so we needed to rename them. Did it in new dir - after_rna_remove.



```{bash, eval=F, echo=T}
mkdir after_rna_remove 
cp id.txt ./after_rna_remove/id_1.txt
mv *_rna_removed* after_rna_remove 
```



```{bash, eval=F, echo=T}
vi for_rename.sh
```



And we again used simple bash code to do the operation for each pair of reads:



```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
        mv ${ID}_rna_removed.1 ${ID}_rna_removed_1_F.fastq
        mv ${ID}_rna_removed.2 ${ID}_rna_removed_2_R.fastq

done < $FILE

```




```{bash, eval=F, echo=T}
chmod +x for_rename.sh
```



Create fastqc report to that over-represented sequences a little loss. 



```{bash, eval=F, echo=T}
mkdir fastq_reports_after_rna_remove
fastqc -o fastq_reports_after_rna_remove *fastq
```



## MultiQC



```{bash, eval=F, echo=T}
multiqc fastq_reports_after_rna_remove
```



-----------------------------------------
For now, we stopped at this step, because we just wanted to try different ways to clean up the data. 

Since we did not plan to collect the transcript, but align it with a ready-made transcript assembled 

from completely purified reads, this should not have hindered us in further analysis.
----------------------------------------



# SALMON



## Indexind ref. transcriprome



```{bash, eval=F, echo=T}
gzip Tr_assem.fasta
```



```{bash, eval=F, echo=T}

cd /path_to/Transcriptome_assembly

/path_to/salmon-latest_linux_x86_64/bin/salmon index -t Tr_assem.fasta.gz -i ref_index_Tr_assem

```



```{bash, eval=F, echo=T}
vi for_salmon_quant.sh
```




## Counting counts



```{bash, eval=F, echo=T}
#!/bin/bash

FILE=$1
while read ID
do
echo "Processing sample ${ID}"

# SRR11096631_rna_removed_2_R.fastq
/path_to/salmon quant -i /path_to/ref_index_Tr_assem -l A \
         -1 /path_to/${ID}_rna_removed_1_F.fastq \
         -2 /path_to/${ID}_rna_removed_2_R.fastq \
         -p 14 --validateMappings -o ${ID}_quant

done < $FILE
```

```{bash, eval=F, echo=T}
chmod +x for_salmon_quant.sh

for_salmon_quant.sh /path_to/id.txt
```

# ==================

# EdgeR

## Install packages

We tried to install the required packages using the usual method, but nothing came of it.

```{r}
install.packages("tximport")
install.packages("edgeR")
```


So we found solution there - <https://bioconductor.org/install/>. 

"If" statement is checking if we already had BiocManager package installed, if not then install it. We needed this package to install other bioconductor packages (edgeR, mixOmics, RColorBrewer).


```{r}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
```


For package installation we used function from - <https://stackoverflow.com/a/31620488>. It will check for missing packages and install them + it will query both - CRAN and Bioconductor repositories for missing package.

```{r}
install.packages.auto <- function(x) { 
  x <- as.character(substitute(x)) 
  if(isTRUE(x %in% .packages(all.available=TRUE))) { 
    eval(parse(text = sprintf("require(\"%s\")", x)))
  } else { 
    #update.packages(ask= FALSE) #update installed packages.
    eval(parse(text = sprintf("install.packages(\"%s\", dependencies = TRUE)", x)))
  }
  if(isTRUE(x %in% .packages(all.available=TRUE))) { 
    eval(parse(text = sprintf("require(\"%s\")", x)))
  } else {
    source("http://bioconductor.org/biocLite.R")
    #biocLite(character(), ask=FALSE) #update installed packages.
    eval(parse(text = sprintf("biocLite(\"%s\")", x)))
    eval(parse(text = sprintf("require(\"%s\")", x)))
  }
}
```

Packages installation:

```{r}
install.packages.auto(tximport)
install.packages.auto(edgeR)
install.packages.auto(mixOmics)
install.packages.auto(RColorBrewer)
install.packages.auto(ggplot2)


BiocManager::install("HTSFilter")

# install.packages("readxl")
# install.packages("stringr")
# install.packages("readr")
# BiocManager::install("biomaRt")
```

Library packages:

```{r}
library(tximport)
library(edgeR)
library(mixOmics)
library(RColorBrewer)
library(ggplot2)
library("readxl")

library(HTSFilter)

# for trouble with tximport transcript missing
library(dplyr)
library(stringr)
library("readr")
library("biomaRt")
```

```{r}
# BiocManager::install("HTSFilter")
library(HTSFilter)
```

==========================================================

## Prepairing data 

"In quant.sf we obtained a table of counts, but for each transcript. The counts are fractional numbers. You also have normalized counts (per million reads), and information on the "real" transcript length and an "effective" length that can be used for normalization, which takes into account several biases." 


### tximport


#### Import annotation: 

```{r}
for_tx2gene <- read.delim("/home/anna/temp/tr_annot.xls")
colnames(for_tx2gene)
```



in  our assemly fasta file:

```{bash, eval=F, echo=T}
>TRINITY_DN174516_c0_g1_i1 len=210 path=[188:0-209] [-1, 188, -2]
CCATTGTCGGTACCATCCTTCTCCTCGTCATCTGCGGTGCCTGCTTCCTCATCATGAAGA
AGACCTCCGACAAGAACGTCGAGCAGATCGTTGCCGGCCGGACCGCCCAGTTTGACTACT
CTTCGACCTCGTCCTCTTCCGAGTTTGCTGGTGCCAACCAGTTTGCTGACCTCGACTACT
ACTCGTACTCGTACTAAGGCGTGTGAAAAC
```

So we need to put transcript_id data (with "TRINITY_DN174516_c0_g1_i1") in the first column in tx2gene file

```{r}
head(for_tx2gene[,c(2,1)])
tx2gene <- for_tx2gene[,c(2,1)]
```

#### Impotr Salmon quant output (quant.sf)

```{r}
samples_names <- c( "SRR11096629_quant", "SRR11096639_quant", "SRR11096640_quant", "SRR11096623_quant", "SRR11096624_quant", "SRR11096625_quant",  "SRR11096626_quant", "SRR11096627_quant", "SRR11096628_quant",  "SRR11096637_quant", "SRR11096638_quant", "SRR11096622_quant")

files <- file.path("/home/anna/temp/for_quant_sf", samples_names, "quant.sf")
names(files) <- paste0("s_", 1:12, c("_auto_bud", "_auto_bud", "_auto_bud", "_avi_bud", "_avi_bud", "_avi_bud", "_auto_mat", "_auto_mat", "_auto_mat",  "_avi_mat", "_avi_mat", "_avi_mat"))

files
```


```{r}
txi.salmon <- tximport(files, type = "salmon", tx2gene = tx2gene)

```

```{r}
cts <- txi.salmon$counts
normMat <- txi.salmon$length
normMat <- normMat/exp(rowMeans(log(normMat)))
o <- log(calcNormFactors(cts/normMat)) + log(colSums(cts/normMat))
group = c(1,1,1,2,2,2,3,3,3,4,4,4) # add groups 

y <- DGEList(cts, group = group)
y$offset <- t(t(log(normMat)) + o)
```


# Filtering

```{r}
keep <- filterByExpr(y)
y <- y[keep, , keep.lib.sizes=FALSE]
```

```{r}
y
```

```{r}
nrow(y$counts)
```

# Normalisation - Effective library sizes

```{r}
y <- calcNormFactors(y)
y$samples
```

```{r}
nrow(y$counts)
```

## PcoA (MDS plot)

```{r}
samples_names_hum <- paste0(c(29,39,40, 23,24,25, 26,27,28, 37,38,22), c("_auto_bud", "_auto_bud", "_auto_bud", "_avi_bud", "_avi_bud", "_avi_bud", "_auto_mat", "_auto_mat", "_auto_mat",  "_avi_mat", "_avi_mat", "_avi_mat"))
plotMDS(y, col= c(1,1,1,2,2,2,3,3,3,4,4,4), labels = samples_names_hum)
```


========================================
## no design

```{r}
y <- estimateDisp(y)
y
```
### estimate disp
```{r}
y$common.dispersion
```
### plotBCV
```{r}
plotBCV(y)
```


### Boxplot for pseudo-counts

```{r}
pseudoCounts <- log2(y$counts + 1)
head(pseudoCounts)
```



```{r}
par(mar = c(8,4,1,2))
boxplot(pseudoCounts, col = "gray", las = 3, cex.names = 1)
```

### MA-plots between first two WT samples (using limma package)
```{r}
limma::plotMA(pseudoCounts[ ,1:2], xlab = "M", ylab = "A", main = "")
abline(h = 0, col = "red")
```

### Heatmap

```{r}
sampleDists <- as.matrix(dist(t(pseudoCounts)))
sampleDists
```


```{r}
cimColor <- colorRampPalette(rev(brewer.pal(9, "Blues")))(8)
cim(sampleDists, color = cimColor, symkey = FALSE, row.cex = 0.7, col.cex = 0.7) # vvedi eto v consol
```

```{r}
dgeFilt <- HTSFilter(y)$filteredData
```


#### topTags

```{r}
fit <- glmFit(dgeFilt)
dgeLRTfilt <- glmLRT(fit, coef = 2)
resLRTfilt <- topTags(dgeLRTfilt, n = nrow(dgeFilt$counts))
selectedFilt <- resLRTfilt$table$FDR < 0.05 & abs(resLRTfilt$table$logFC) > 1
selectedFilt <- resLRTfilt$table[selectedFilt, ]
nrow(selectedFilt)
```

```{r}
head(selectedFilt)
```


# ================================
## with design

### estimatind disp


Create a table with experiment design:

```{r}
samples_names_hum <- paste0(c(29,39,40, 23,24,25, 26,27,28, 37,38,22), c("_auto_bud", "_auto_bud", "_auto_bud", "_avi_bud", "_avi_bud", "_avi_bud", "_auto_mat", "_auto_mat", "_auto_mat",  "_avi_mat", "_avi_mat", "_avi_mat"))

zooid_type <- c('AU','AU','AU', 'av', 'av', 'av','AU','AU','AU', 'av', 'av', 'av')

age <- c('b', 'b', 'b', 'b', 'b', 'b', 'M', 'M', 'M', 'M', 'M', 'M')

all_against_all <- c(1:12)

each_sample <- c(1,1,1,2,2,2,3,3,3,4,4,4)

metadata <- data.frame(samples_names_hum, zooid_type, age, all_against_all, each_sample)
metadata
```


#### ~age + zooide type

```{r}
design_age_zooide_type<- model.matrix(~age + zooid_type, data = metadata)
rownames(design_age_zooide_type) <- samples_names_hum
design_age_zooide_type
```

```{r}
tab_age_zooide_type <- estimateDisp(y, design_age_zooide_type, robust=TRUE)
tab_age_zooide_type$common.dispersion
```


```{r}
plotBCV(tab_age_zooide_type)
```

### PLOTS With DESIGN

```{r}
pseudoCounts <- log2(y$counts + 1)
head(pseudoCounts)
```


#### Boxplot for pseudo-counts
```{r}
par(mar = c(8,4,1,2))
boxplot(pseudoCounts, col = "gray", las = 3, cex.names = 1)
```

#### MA-plots between first two WT samples (using limma package)
```{r}
limma::plotMA(pseudoCounts[ ,1:2], xlab = "M", ylab = "A", main = "")
abline(h = 0, col = "red")
```

#### Heatmap

```{r}
sampleDists <- as.matrix(dist(t(pseudoCounts)))
sampleDists
```


```{r}
cimColor <- colorRampPalette(rev(brewer.pal(9, "Blues")))(8)
cim(sampleDists, color = cimColor, symkey = FALSE, row.cex = 0.7, col.cex = 0.7) # vvedi eto v consol
```




```{r}
dgeFilt <- HTSFilter(y)$filteredData
```


```{r}
dgeFilt
```

###### topTags

```{r}
fit <- glmFit(dgeFilt)
dgeLRTfilt <- glmLRT(fit, coef = 2)
resLRTfilt <- topTags(dgeLRTfilt, n = nrow(dgeFilt$counts))
selectedFilt <- resLRTfilt$table$FDR < 0.05 & abs(resLRTfilt$table$logFC) > 1
selectedFilt <- resLRTfilt$table[selectedFilt, ]
nrow(selectedFilt)
```

```{r}
head(selectedFilt)
```


# MA plot with differentially expressed genes (-----)

plotSmear(dgeFilt, de.tags = rownames(selectedFilt))
```{r}
dgeFilt$samples$group <- design_age_zooide_type

```
```{r}

```


```{r}
selY <- cpm(dgeFilt, log = TRUE, prior.count = 1)
selY <- selY[match(rownames(selectedFilt), rownames(dgeFilt$counts)), ]
finalHM <- cim(t(selY), color = cimColor, symkey = FALSE, row.cex = 0.7,
               col.cex = 0.7)
```



































```{r}
sessionInfo()
```

